# Big-Data-Analysis

COMPANY : CODTECH IT SOLUTIONS

NAME : REEEMALI YASASWINI

INTERN ID :CT04DF303

DOMAIN : DATA ANALYTICS

DURATION : 4 WEEKS

MENTOR : NEELA SANTOSH

TASK DESCRIPTION : This Big Data Analysis project focuses on performing large-scale data processing and insights extraction from the New York City Taxi Trip Dataset using Apache Spark. The project leverages Spark’s distributed computing capabilities to efficiently handle millions of trip records stored in Parquet format, making it ideal for analyzing real-world, high-volume transportation data. Developed using PySpark in a local Spark environment, the main goal of the project is to understand trip patterns, passenger behavior, and fare trends across New York City. The dataset includes critical fields like pickup and drop-off timestamps, trip distances, passenger count, payment types, and fare amounts. The analysis pipeline involves reading the Parquet files into Spark DataFrames, conducting data cleansing (removing nulls and outliers), and performing meaningful aggregations, such as calculating average trip duration, identifying peak travel hours, most common pickup locations, revenue trends per vendor, and more. Additional transformations such as date-time feature extraction and filtering based on business rules enhance the insights derived. Visualizations were optionally done using Python libraries like matplotlib or integrated BI tools such as Power BI or Tableau (if used), to make findings more interpretable. The project also includes performance tuning practices like caching and partitioning to demonstrate efficient Spark operations. All scripts are modular and well-structured, ensuring scalability and adaptability for larger datasets or new questions. The use of Spark SQL further allows for expressive querying of big datasets in a SQL-like syntax. This project not only showcases a practical application of Big Data processing but also demonstrates end-to-end data engineering workflow — from raw data ingestion to insight generation. It was developed and tested using VS Code and the Spark Shell, and it reflects key industry-level data processing strategies that are essential for data engineers and analysts working in real-time analytics and transportation domains. Overall, this project highlights the power of distributed processing and Spark’s role in transforming massive datasets into actionable business insights.

OUTPUT : ![Image](https://github.com/user-attachments/assets/89cea330-8af6-458e-ae17-ff9e72f676ef)

![Image](https://github.com/user-attachments/assets/19ec8b5b-1d13-4c51-b744-ed82a02bfcde)

![Image](https://github.com/user-attachments/assets/536a0484-72c0-46f4-a8be-9477d626305f)

